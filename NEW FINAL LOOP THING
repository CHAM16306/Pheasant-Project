library(scrm)
library(stringr)
library(locfit)
library(carData)
library(car)
library(Rfast)
library(FSA)

sessionInfo()

#Kardos et al. 2015. He describes two measures of homozygosity - one where you look only at the minor allele frequency, and one where you look at both the minor and major alleles across the population. Kardos et al. 2015 (and everyone who uses PLINK to calculate homozygosity) uses the prior method: 
#sum of (1-2p(1-p))
#where p is the minor allele frequency at locus 1 across the whole population. 


1.33E-09

#First we vdescribed our variables:
nhap=44#2*number of samples i.e. number of pheasante in real data (bc diploid) 
#2 seperate simulations, one for malaysian (20 indv) and mountain (22 indv)
nrep=1000#min 100, 1000 if fast enough
bp=1000000
N0=500 #effective population ≠ census size, mention in report!
T1=50/(4*(N0)) #time at bottleneck
N1=40 #pop at bottlneck
N2=150000 #ancestral pop
G=-(1/T1)*log(N1/(N0)) #exponential growth rate after bottleneck
a2=0 #exponential/constant growth rate in ancestral pop
theta0=4*(N0)*(1.33*10^-9)*bp #with 1.33*10^-9 = mutationrate per yer (=generation) per locus
p=N1/N2 #pop proportion at bottleneck (bottleneck/ancestral pop)
r = 0.03 #crossover probability between the two ends of the locus bc 3cM/Mb = 0.03% chance of crossover in the region
rho = 4*r*N0 #recombination rate

#mimic real data
#if  this happens (object has no variables), do heterozygosity
#with small seq by chance th eprobabilty of having a varient is v low ( all indv the same) 

Fh = matrix(ncol = nrep,nrow=nhap/2) #make columns for each iteration, with the number of rows = nbr of inividuals
#Fh calculated with only minor allele frequency (see Keller et al.)
G.EHet = matrix(nrow = nrep) #Global heterozygosity (Rita's formula)
G.EHom = matrix(nrow = nrep)

Fis = matrix(ncol = nrep,nrow=nhap/2)
for(a in 1:nrep) #loop it nrep times
{
  command = paste(nhap, 1, "-t",theta0, "-G",G, "-eG",T1,a2, "-eN",T1,p, "-r",rho,bp , "-print-model")
  scrm.data<-scrm(command, file="test1")
  write.table(scrm.data, file = paste("tabledata",a, ".txt",sep = "")) #write a table for each loop and paste file in directory
  
  scrm.df=as.data.frame(scrm.data) #coerce to class data.frame
  
  if(dim(scrm.df)[2]==0){ #bc low mutation rate sometimes no variants; to avoid this, tell loop to make G.EHet and Fh equal 0 if the dimensions of the columns [2] of scrm.df are 0 (bc if dim = 0 that means no diversity which means there is no heterozygosity, only homozygosity)
    
    Fh[,a]<-1 #high values = inbreeding (more homozygotes), i.e. no variation and range form -1 to 1
    # G.EHet[a]<-0 
    # G.EHom[a]<-1
    Fis[,a]<-1 #pos values = inbreeding, i.e. no variation and range form -1 to 1 
    
  }
  
  else{#if the dim ≠ 0 then just rin loop normally
    
    shuffled.data <- scrm.df[sample(nrow(scrm.df)),] #shuffle the rows
    shuffled.matrix <- data.matrix(shuffled.data, rownames.force = NA) #Convert a Data Frame to a Numeric Matrix
    diploid.data <- rowsum(shuffled.matrix, as.integer(gl(nrow(shuffled.matrix), 2, nrow(shuffled.matrix)))) #combine 2 rows into 1 (haploid into diploid)
    named.diploid <- ifelse(diploid.data %% 2 == 0,"Hom","Het") #if dividable by 2 and remainder 0, then name "Hom", if not name "Het"
    
    n.loci <- ncol(shuffled.matrix)
    #number of loci (i.e. segsites)
    
    Hom_per_row = numeric() #Homozygosity per colum by counting the "Hom"s
    
    for (i in 1:nhap/2)#nbr of rows, that's how many individuals we have
    {
      Hom_per_row[i] = sum(str_count(named.diploid[i,], "Hom"))/n.loci #number of hom divided by number of loci (frequency of hom per number of loci)
    }
    #number of hom divided by number of loci (frequency of hom per number of loci) 
    
    M1_per_col = numeric() #allele frequency of 1s
    M0_per_col = numeric() #allele frequency of 0s
    maf = numeric() #minor allele frequency
    EHom = numeric() #Expected Homozygosity
    for (i in 1:n.loci) #calculations per loci (i.e. columns) not individuals
      
      #count number of ones and zeros and depending on which is smaller use that one to calculate the minor allele frequency
    {
      M1_per_col[i] = sum(str_count(shuffled.matrix[,i], "1")) #count all the 1 (=mutation, whereas 0 are the ancestral state) for each segsite
      M0_per_col[i] = sum(str_count(shuffled.matrix[,i], "0")) #count all the 1 (=mutation, whereas 0 are the ancestral state) for each segsite
      if (M1_per_col[i] >=  M0_per_col[i]) #if number of M1 > M0, then us e M0 as the minor allele ferquency
      {
        
        maf[i]=M0_per_col[i]/nhap #number of hom per column, divided by total number of rows (2*individuals), so maf per loci
        EHom[i]=1-2*maf[i]*(1-maf[i])  #expected homozygosity per locus across the whole population
      }
      else
      {
        maf[i]=M1_per_col[i]/nhap #number of hom per column, divided by total number of rows (2*individuals), so maf per loci
        EHom[i]=1-2*maf[i]*(1-maf[i])  #expected homozygosity per locus across the whole population
      }
    }
    
    SEHom = mean(EHom)# expected mean number of homozygous genotypes across m loci
    #leave you with one value
    
    Fh[,a]= (Hom_per_row-SEHom)/(n.loci-SEHom) #Fh as proxy for inbreeding
    Fh.test= (Hom_per_row-SEHom)/(n.loci-SEHom)
    #if (Hom_per_row-SEHom) = (n.loci-SEHom), i.e. Hom_per_row = n.loci, then Fh = 1 
    #negative when Hom_per_row < SEHom and 
 
    #deviation of the observed heterozygosity of an individual relative to the heterozygosity expected under random mating (Hardy–Weinberg equilibrium)
    #Fis=1−Ho/He. Fis>0 signifies more inbreeding than is expected at random, whereas Fis<0 indicates that inbreeding occurred less often than would be expected at random.
    
    Het_per_row = numeric() #Homozygosity per colum by counting the "Hom"s
    
    for (i in 1:nhap/2)#nbr of rows, that's how many individuals we have
    {
      Het_per_row[i] = sum(str_count(named.diploid[i,], "Het"))/n.loci #number of hom divided by number of loci (frequency of hom per number of loci)
    }
    
    
    Fis.Mut_per_col = numeric() #number of allele 1 per column
    Fis.maf = numeric() #major allele frequency ratio = number of 1 divided by total number of alleles = p (because ratio)
    Fis.Min.mut_per_col=numeric() #number of allele 0 per column
    Fis.min.af = numeric() #minor allele frequency ratio = number of 0 divided by total number of alleles =p
    Fis.total.allele.freq=numeric() #sum of p^2 (individual observed homozygosity)
    EHet = numeric() 
    for (i in 1:n.loci)
    {
      Fis.Mut_per_col[i] = sum(str_count(shuffled.matrix[,i], "1")) #count all the 1 (=mutation, whereas 0 are the ancestral state) for each segsite
      Fis.maf[i]=Fis.Mut_per_col[i]/nhap #number of hom per column, divided by total number of rows (2*individuals), so maf per loci
      Fis.Min.mut_per_col[i] = sum(str_count(shuffled.matrix[,i], "0")) #count all the 0 (=mutation, whereas 0 are the ancestral state) for each segsite
      Fis.min.af[i] = Fis.Min.mut_per_col[i]/nhap
      Fis.total.allele.freq[i]=  (Fis.maf[i])^2 + (Fis.min.af[i])^2 #sum of p^2
      
  #He = expected heterozygosity = 1 − Sum pi^2.
      
      #EHom[i]=1-2* Fis.total.allele.freq[i]*(1- Fis.total.allele.freq[i])
      #SEHom = mean(EHom)# expected mean number of homozygous genotypes across m loci
     
      EHet[i]= 1- Fis.total.allele.freq[i]
      #SEHet = mean(EHet)# expected mean number of homozygous genotypes across m loci
      
      #Fis[,a]= 1-((Hom_per_row)/SEHom)
      Fis[,a]= 1-((Het_per_row)/EHet)
      
    }
  }
}


#write about how x % of the simualations had no diversity (where Fh = 0, get rif pf these)
##################################################################################################################
#Save Fh and Fis values - DO NOT OVERWRITE

Fh.2.sim = Fh
Fh.4.sim = Fh
Fh.6.sim = Fh
Fh.8.sim = Fh
Fh.10.sim = Fh
Fh.20.sim = Fh
Fh.40.sim = Fh

Fis.2.sim = Fis
Fis.4.sim = Fis
Fis.6.sim = Fis
Fis.8.sim = Fis
Fis.10.sim = Fis
Fis.20.sim = Fis
Fis.40.sim = Fis


##################################################################################################################
#Plot Fh using the mean

#mean Fh per iteration (col = iteration)
Fh.means.2=colMeans(Fh.2.sim) 
Fh.means.4=colMeans(Fh.4.sim)
Fh.means.6=colMeans(Fh.6.sim)
Fh.means.8=colMeans(Fh.8.sim)
Fh.means.10=colMeans(Fh.10.sim)
Fh.means.20=colMeans(Fh.20.sim)
Fh.means.40=colMeans(Fh.40.sim)

#Use the locfit function for nicer curves
Fh.2.loc.f=locfit(~Fh.means.2, maxk=130, alpha = 0.9) #~x for a density estimation model
Fh.4.loc.f=locfit(~Fh.means.4, maxk=130, alpha = 0.9) 
Fh.6.loc.f=locfit(~Fh.means.6, maxk=130, alpha = 0.9) 
Fh.8.loc.f=locfit(~Fh.means.8, maxk=130, alpha = 0.9) 
Fh.10.loc.f=locfit(~Fh.means.10, maxk=130, alpha = 0.9) 
Fh.20.loc.f=locfit(~Fh.means.20, maxk=130, alpha = 0.9) 
Fh.40.loc.f=locfit(~Fh.means.40, maxk=130, alpha = 0.9) 

#plot
plot(Fh.2.loc.f, xlab="Fh", ylab="Density", ylim=c(0,32), xlim=c(-0.1,0.1), col="firebrick2")
lines(Fh.4.loc,f, col="blue1")
lines(Fh.6.loc.f, col="green")
lines(Fh.8.loc.f, col="orange")
lines(Fh.10.loc.f, col="gray14")
lines(Fh.20.loc.f, col="purple")
lines(Fh.40.loc.f, col="deepskyblue")
abline(v=mean.Fh.mount,lty=2) #line to show the mean Fh for the real pheasant data

colours = c("firebrick2", "blue1", "green", "orange", "gray14", "purple", "deepskyblue")
legend("topright", legend=c("Fh.2","Fh.4", "Fh.6","Fh.8","Fh.10","Fh.20","Fh.40"), col = colours, cex=0.8, fill= colours, bty="n")

##################################################################################################################
#Plot Fh using the median

# median Fh per inividual
Fh.median.2=colMedians(Fh.2.sim)
Fh.median.4=colMedians(Fh.4.sim)
Fh.median.6=colMedians(Fh.6.sim)
Fh.median.8=colMedians(Fh.8.sim)
Fh.median.10=colMedians(Fh.10.sim)
Fh.median.20=colMedians(Fh.20.sim)
Fh.median.40=colMedians(Fh.40.sim)

#Use the locfit function for nicer curves
Fh.2.loc.mf=locfit(~Fh.median.2) #~x for a density estimation model
Fh.4.loc.mf=locfit(~Fh.median.4) 
Fh.6.loc.mf=locfit(~Fh.median.6) 
Fh.8.loc.mf=locfit(~Fh.median.8) 
Fh.10.loc.mf=locfit(~Fh.median.10) 
Fh.20.loc.mf=locfit(~Fh.median.20) 
Fh.40.loc.mf=locfit(~Fh.median.40) 

#Plot
plot(Fh.2.loc.mf, xlab="Fh.median", ylab="Density", ylim=c(0,8), xlim=c(-0.2,0.2), col="firebrick2")
lines(Fh.4.loc,mf, col="blue1")
lines(Fh.6.loc.mf, col="green")
lines(Fh.8.loc.mf, col="orange")
lines(Fh.10.loc.mf, col="gray14")
lines(Fh.20.loc.mf, col="purple")
lines(Fh.40.loc.mf, col="deepskyblue")
abline(v=median.Fh.mount,lty=2) #line to show the mean Fh for the real pheasant data

colours = c("firebrick2", "blue1", "green", "orange", "gray14", "purple", "deepskyblue")
legend("topright", legend=c("Fh.2","Fh.4", "Fh.6","Fh.8","Fh.10","Fh.20","Fh.40"), col = colours, cex=0.8, fill= colours, bty="n")


##################################################################################################################
#Plot Fis using the mean


Fis.means.2=colMeans(Fis.2.sim) 
Fis.means.4=colMeans(Fis.4.sim)
Fis.means.6=colMeans(Fis.6.sim)
Fis.means.8=colMeans(Fis.8.sim)
Fis.means.10=colMeans(Fis.10.sim)
Fis.means.20=colMeans(Fis.20.sim)
Fis.means.40=colMeans(Fis.40.sim)

#Locfit function
Fis.2.loc.f=locfit(~Fis.means.2, alpha = 0.9) #~x for a density estimation model
Fis.4.loc.f=locfit(~Fis.means.4, alpha = 0.9) 
Fis.6.loc.f=locfit(~Fis.means.6, alpha = 0.9) 
Fis.8.loc.f=locfit(~Fis.means.8, alpha = 0.9) 
Fis.10.loc.f=locfit(~Fis.means.10, alpha = 0.9) 
Fis.20.loc.f=locfit(~Fis.means.20, alpha = 0.9) 
Fis.40.loc.f=locfit(~Fis.means.40, alpha = 0.9) 

#Plot
plot(Fis.2.loc.f, xlab="Fis", ylab="Density", ylim=c(0, 10), xlim=c(-0.2,0.2), col="firebrick2")
lines(Fis.4.loc.f, col="blue1")
lines(Fis.6.loc.f, col="green")
lines(Fis.8.loc.f, col="orange")
lines(Fis.10.loc.f, col="gray14")
lines(Fis.20.loc.f, col="purple")
lines(Fis.40.loc.f, col="deepskyblue")
abline(v=Fis.mount.mean,lty=2) #line to show the mean Fh for the real pheasant data
abline(v=0,lty=2)
colours = c("firebrick2", "blue1", "green", "orange", "gray14", "purple", "deepskyblue")
legend("topright", legend=c("Fh.2","Fh.4", "Fh.6","Fh.8","Fh.10","Fh.20","Fh.40"), col = colours, cex=0.8, fill= colours, bty="n")

#Fis=1−Ho/He. 
#Fis>0 signifies more inbreeding than is expected at random. 
#Fis<0 indicates that inbreeding occurred less often than would be expected at random.


##################################################################################################################
#Plot Fh using the median

# median Fh per inividual
Fis.median.2=colMedians(Fis.2.sim)
Fis.median.4=colMedians(Fis.4.sim)
Fis.median.6=colMedians(Fis.6.sim)
Fis.median.8=colMedians(Fis.8.sim)
Fis.median.10=colMedians(Fis.10.sim)
Fis.median.20=colMedians(Fis.20.sim)
Fis.median.40=colMedians(Fis.40.sim)

#Use the locfit function for nicer curves
Fis.2.loc.mf=locfit(~Fis.median.2) #~x for a density estimation model
Fis.4.loc.mf=locfit(~Fis.median.4) 
Fis.6.loc.mf=locfit(~Fis.median.6) 
Fis.8.loc.mf=locfit(~Fis.median.8) 
Fis.10.loc.mf=locfit(~Fis.median.10) 
Fis.20.loc.mf=locfit(~Fis.median.20) 
Fis.40.loc.mf=locfit(~Fis.median.40) 

#Plot
plot(Fis.2.loc.mf, xlab="Fis.median", ylab="Density", ylim=c(0,6), xlim=c(-0.7,0.7), col="firebrick2")
lines(Fis.4.loc,mf, col="blue1")
lines(Fis.6.loc.mf, col="green")
lines(Fis.8.loc.mf, col="orange")
lines(Fis.10.loc.mf, col="gray14")
lines(Fis.20.loc.mf, col="purple")
lines(Fis.40.loc.mf, col="deepskyblue")
abline(v=median.Fh.mount,lty=2) #line to show the mean Fh for the real pheasant data

colours = c("firebrick2", "blue1", "green", "orange", "gray14", "purple", "deepskyblue")
legend("topright", legend=c("Fh.2","Fh.4", "Fh.6","Fh.8","Fh.10","Fh.20","Fh.40"), col = colours, cex=0.8, fill= colours, bty="n")



##################################################################################################################
#ANOVA - Fh


yfh=c(Fh.means.2, Fh.means.4, Fh.means.6, Fh.means.8, Fh.means.10, Fh.means.20, Fh.means.40)
xfh=c(1,2,3,4,5,6,7)
xfh.factor =as.factor(xfh)
aov.data.Fh.f <- data.frame(yfh, xfh.factor) #make dataframe where x is a factor and y is numeric
str(aov.data.Fh.f) #look at dataframe


aov.out.Fh.f = aov(yfh ~ xfh.factor, data=aov.data.Fh.f)
summary(aov.out.Fh.f)
summary.lm(aov.out.Fh.f)#non sig
TukeyHSD(aov.out.Fh.f)#non sig


# #Testing the assumptions
# 
# bartlett.test(y2 ~ x2.factor, data=aov.data.Fh) #Homogeneity of variance
# #Significant result, therefore variances cannot be assumed to be equal?
# 
# #Check the normality assumption
# plot(aov.out.Fh, 2) #Model checking plots
# #As all the points fall approximately along this reference line, we can assume normality.
# 
# #Check the homogeneity of variance assumption
# leveneTest(y2 ~ x2.factor, data = aov.data.Fh) #p-value is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance across groups is statistically significantly different. Therefore, we can assume the homogeneity of variances in the different treatment groups.
# plot(aov.out.Fh, 1)
# #Points 24, 57, 62 are detected as outliers, which can severely affect normality and homogeneity of variance. It can be useful to remove outliers to meet the test assumptions.
# 
# #normality test
# shapiro.test(resid(aov.out.Fh))
# #non significant


#Non-parametric alternative to ANOVA:
kruskal.test(yfh ~ xfh.factor, data=aov.data.Fh.f)


#Transform the data using log
logyfh <- log(1+yfh)
xfh=c(1,2,3,4,5,6,7)
xfh.factor =as.factor(xfh)
aov.data.Fh.log.f <- data.frame(logyfh, xfh.factor) #make dataframe where x is a factor and y is numeric
str(aov.data.Fh.log.f) #look at dataframe

aov.out.Fh.log.f = aov(logyfh ~ xfh.factor, data=aov.data.Fh.log.f)
summary(aov.out.Fh.log.f)
summary.lm(aov.out.Fh.log.f)#non sig
TukeyHSD(aov.out.Fh.log.f)#non sig


kruskal.test(logyfh ~ xfh.factor, data=aov.data.Fh.log.f)


##################################################################################################################
#ANOVA - Fis


yfis=c(Fis.means.2, Fis.means.4, Fis.means.6, Fis.means.8, Fis.means.10, Fis.means.20,Fis.means.40)
xfis=c(1,2,3,4,5,6,7)
xfis.factor =as.factor(xfis)
aov.data.Fis.f <- data.frame(yfis, xfis.factor) #make dataframe where x is a factor and y is numeric
str(aov.data.Fis.f) #look at dataframe

aov.out.Fis.f = aov(yfis ~ xfis.factor, data=aov.data.Fis.f)
summary(aov.out.Fis.f)
summary.lm(aov.out.Fis.f)#non sig
TukeyHSD(aov.out.Fis.f)#non sig

#Testing the assumptions
# 
# bartlett.test(y3 ~ x3.factor, data=aov.data.Fis) #Homogeneity of variance
# #Significant result, therefore variances cannot be assumed to be equal?
# 
# #Check the normality assumption
# plot(aov.out.Fis, 2) #Model checking plots
# #As all the points fall approximately along this reference line, we can assume normality.
# 
# #Check the homogeneity of variance assumption
# leveneTest(y3 ~ x3.factor, data = aov.data.Fis) #p-value is not less than the significance level of 0.05. This means that there is no evidence to suggest that the variance across groups is statistically significantly different. Therefore, we can assume the homogeneity of variances in the different treatment groups.
# plot(aov.out.Fis, 1)
# #Points 24, 57, 62 are detected as outliers, which can severely affect normality and homogeneity of variance. It can be useful to remove outliers to meet the test assumptions.
# 
# #normality test
# shapiro.test(resid(aov.out.Fis))
# #non significant



#Non-parametric alternative to ANOVA:
kruskal.test(yfis ~ xfis.factor, data=aov.data.Fis.f)






